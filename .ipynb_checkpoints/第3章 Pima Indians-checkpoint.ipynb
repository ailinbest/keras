{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renal/data01/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 加载并切分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('./pima-indians-diabetes.data.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.创建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这个例子中设置了一个三层神经网络，第一层有12个神经元，第二个有8个神经元，第三个有1个神经元\n",
    "- 使用Sequential初始化一个模型，并添加连接层\n",
    "- Dense类来定义完全连接层，第一个参数是unit，表示神经元的个数，input_dim指定输入层的维度，并用activation指定激活函数\n",
    "- Keras默认把W初始化为介于0~0.05之间的符合高斯分布的随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/renal/data01/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 编译模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 必须指定损失函数(loss)，优化器（optimizer）和metrics\n",
    "- 对于二分类问题使用对数交叉熵（binary_crossentropy）\n",
    "- 优化器：梯度下降算法Adam，这个是什么算法？\n",
    "- accuracy作为分类评估标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- epochs指定迭代的次数\n",
    "- batch_size:每个批次中有实例的个数\n",
    "- 参数validation_split把整个数据集进行分割，一部分是训练集，一部分为验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/renal/data01/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s 592us/step - loss: 3.7119 - acc: 0.5977\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.9373 - acc: 0.5951\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.7506 - acc: 0.6393\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.7117 - acc: 0.6445\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.6804 - acc: 0.6862\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6508 - acc: 0.6797\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6491 - acc: 0.6732\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.6358 - acc: 0.6888\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.6243 - acc: 0.6927\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.6289 - acc: 0.6771\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.6482 - acc: 0.6719\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.6401 - acc: 0.6745\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.6255 - acc: 0.6797\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.6166 - acc: 0.7005\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.6019 - acc: 0.6992\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.5869 - acc: 0.7031\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.5849 - acc: 0.7005\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5991 - acc: 0.6888\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5808 - acc: 0.7096\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5800 - acc: 0.7174\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5694 - acc: 0.7096\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.5826 - acc: 0.6966\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.5742 - acc: 0.7135\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.5683 - acc: 0.7305\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.5575 - acc: 0.7383\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5710 - acc: 0.7031\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.5561 - acc: 0.7161\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5560 - acc: 0.7279\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5726 - acc: 0.7214\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.5609 - acc: 0.7214\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.5681 - acc: 0.7188\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5644 - acc: 0.7122\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5517 - acc: 0.7214\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5474 - acc: 0.7305\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5496 - acc: 0.7253\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5654 - acc: 0.7018\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5330 - acc: 0.7383\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.5391 - acc: 0.7279\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.5463 - acc: 0.7161\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5441 - acc: 0.7201\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.5423 - acc: 0.7305\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5379 - acc: 0.7409\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5303 - acc: 0.7513\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5333 - acc: 0.7448\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5319 - acc: 0.7565\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.5277 - acc: 0.7487\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5329 - acc: 0.7344\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5316 - acc: 0.7422\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5322 - acc: 0.7526\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.5283 - acc: 0.7357\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.5286 - acc: 0.7461\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5293 - acc: 0.7409\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.5382 - acc: 0.7461\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5349 - acc: 0.7331\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5226 - acc: 0.7487\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5280 - acc: 0.7513\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.5306 - acc: 0.7396\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.5215 - acc: 0.7500\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.5116 - acc: 0.7630\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.5321 - acc: 0.7383\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.5244 - acc: 0.7487\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5158 - acc: 0.7526\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.5428 - acc: 0.7370\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.5287 - acc: 0.7422\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.5205 - acc: 0.7435\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5083 - acc: 0.7526\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.5150 - acc: 0.7370\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5141 - acc: 0.7578\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.5115 - acc: 0.7513\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.5376 - acc: 0.7240\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5155 - acc: 0.7487\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.5169 - acc: 0.7565\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.5150 - acc: 0.7513\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.5095 - acc: 0.7617\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.5104 - acc: 0.7526\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.5123 - acc: 0.7487\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5123 - acc: 0.7578\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.5107 - acc: 0.7539\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.5112 - acc: 0.7526\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.5091 - acc: 0.7617\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.5049 - acc: 0.7708\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.5039 - acc: 0.7526\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4971 - acc: 0.7578\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4974 - acc: 0.7591\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 86us/step - loss: 0.5049 - acc: 0.7487\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.5058 - acc: 0.7474\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.4996 - acc: 0.7513\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4986 - acc: 0.7630\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5060 - acc: 0.7630\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.5080 - acc: 0.7552\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4997 - acc: 0.7526\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5045 - acc: 0.7487\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.4971 - acc: 0.7643\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4967 - acc: 0.7669\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.4997 - acc: 0.7487\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4945 - acc: 0.7656\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4977 - acc: 0.7786\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4876 - acc: 0.7656\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4884 - acc: 0.7695\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4844 - acc: 0.7786\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4874 - acc: 0.7760\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.5017 - acc: 0.7630\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.5000 - acc: 0.7604\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4910 - acc: 0.7878\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.5224 - acc: 0.7487\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4862 - acc: 0.7786\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4880 - acc: 0.7734\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 90us/step - loss: 0.4966 - acc: 0.7812\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4869 - acc: 0.7695\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4920 - acc: 0.7682\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4840 - acc: 0.7812\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4897 - acc: 0.7734\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.4929 - acc: 0.7591\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4931 - acc: 0.7565\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4923 - acc: 0.7773\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4953 - acc: 0.7656\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 90us/step - loss: 0.4899 - acc: 0.7643\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4888 - acc: 0.7786\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4826 - acc: 0.7760\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.4917 - acc: 0.7760\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4912 - acc: 0.7708\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.4870 - acc: 0.7799\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.4838 - acc: 0.7695\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.4833 - acc: 0.7799\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.4882 - acc: 0.7839\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.4794 - acc: 0.7812\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.4902 - acc: 0.7656\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4730 - acc: 0.7695\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.4827 - acc: 0.7721\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.4752 - acc: 0.7904\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.4804 - acc: 0.7734\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.4814 - acc: 0.7852\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.4818 - acc: 0.7760\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.4829 - acc: 0.7799\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.4779 - acc: 0.7813\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4743 - acc: 0.7812\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.4681 - acc: 0.7812\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.4800 - acc: 0.7812\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4653 - acc: 0.7904\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.4833 - acc: 0.7839\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.4738 - acc: 0.7865\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.4840 - acc: 0.7734\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.4769 - acc: 0.7695\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.4762 - acc: 0.7799\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4890 - acc: 0.7682\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.4936 - acc: 0.7734\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.4824 - acc: 0.7786\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.4717 - acc: 0.7747\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4756 - acc: 0.7695\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.4752 - acc: 0.7708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f656cd66080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X,y=Y,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.评估模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 76us/step\n",
      "\n",
      "acc : 79.43%\n"
     ]
    }
   ],
   "source": [
    "#Returns the loss value & metrics values for the model in test mode\n",
    "scores = model.evaluate(x=X,y=Y)\n",
    "print('\\n%s : %.2f%%' %(model.metrics_names[1],scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4688127376139164, 0.7942708333333334]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
